{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ‡§®‡•ã‡§ü‡§¨‡•Å‡§ï 1: PP-OCR ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡•á‡§ü‡§æ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§®‡§æ üìù\n",
    "\n",
    "**‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø:** ‡§á‡§∏ ‡§®‡•ã‡§ü‡§¨‡•Å‡§ï ‡§ï‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§Æ‡§æ‡§®‡§ï ‡§è‡§®‡•ã‡§ü‡•á‡§∂‡§® ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡•à‡§°‡§≤‡§ì‡§∏‡•Ä‡§Ü‡§∞ (PaddleOCR) ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§∂‡§® ‡§î‡§∞ ‡§∞‡§ø‡§ï‡•â‡§ó‡•ç‡§®‡§ø‡§∂‡§® ‡§≤‡•á‡§¨‡§≤ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§ï‡•ã ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°, ‡§Ö‡§®‡§ú‡§º‡§ø‡§™ ‡§î‡§∞ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§π‡•à‡•§ ‡§π‡§Æ ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§µ‡•à‡§≤‡§ø‡§°‡•á‡§∂‡§® ‡§∏‡•á‡§ü ‡§≠‡•Ä ‡§¨‡§®‡§æ‡§è‡§Ç‡§ó‡•á‡•§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 1: ‡§™‡§∞‡§ø‡§µ‡•á‡§∂ ‡§∏‡•á‡§ü‡§Ö‡§™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§™‡•Å‡§∏‡•ç‡§§‡§ï‡§æ‡§≤‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç\n",
    "!pip install opencv-python-headless Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 2: ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§î‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç\n",
    "\n",
    "‡§π‡§Æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§õ‡•ã‡§ü‡•á, ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á‡•§ ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§™‡§∞‡§ø‡§¶‡•É‡§∂‡•ç‡§Ø ‡§Æ‡•á‡§Ç, ‡§Ü‡§™ ‡§Ø‡§π‡§æ‡§Å COCO-Text ‡§Ø‡§æ ICDAR ‡§ú‡•à‡§∏‡•á ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§ï‡•ã ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§î‡§∞ ‡§Ö‡§®‡§ú‡§º‡§ø‡§™ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á‡•§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§ø‡§ï‡§æ‡§è‡§Å ‡§¨‡§®‡§æ‡§è‡§Å\n",
    "os.makedirs('dataset/images', exist_ok=True)\n",
    "os.makedirs('dataset/word_crops', exist_ok=True)\n",
    "\n",
    "# ‡§è‡§ï ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§è‡§®‡•ã‡§ü‡•á‡§∂‡§® ‡§´‡§º‡§æ‡§á‡§≤ ‡§¨‡§®‡§æ‡§è‡§Å (‡§ú‡•à‡§∏‡•á, COCO-Text ‡§∏‡•á)\n",
    "annotations = {\n",
    "    \"img_01.png\": [\n",
    "        {\"transcription\": \"PADDLE\", \"points\": [[10, 15], [100, 16], [99, 50], [11, 49]]},\n",
    "        {\"transcription\": \"OCR\", \"points\": [[120, 20], [180, 20], [180, 55], [120, 55]]}\n",
    "    ],\n",
    "    \"img_02.png\": [\n",
    "        {\"transcription\": \"HELLO\", \"points\": [[25, 30], [150, 28], [151, 80], [26, 82]]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§Æ‡•Ä ‡§õ‡§µ‡§ø‡§Ø‡§æ‡§Å ‡§¨‡§®‡§æ‡§è‡§Å\n",
    "def create_dummy_image(text, path, size=(200, 100)):\n",
    "    img = Image.new('RGB', size, color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 15)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    draw.text((10, 10), text, fill='black', font=font)\n",
    "    img.save(path)\n",
    "\n",
    "create_dummy_image(\"PADDLE OCR\", \"dataset/images/img_01.png\")\n",
    "create_dummy_image(\"HELLO\", \"dataset/images/img_02.png\")\n",
    "\n",
    "print(\"‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 3: ‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§∂‡§® ‡§≤‡•á‡§¨‡§≤ ‡§Æ‡•á‡§Ç ‡§∞‡•Ç‡§™‡§æ‡§Ç‡§§‡§∞‡§£\n",
    "\n",
    "‡§π‡§Æ `det_label.txt` ‡§´‡§º‡§æ‡§á‡§≤ ‡§¨‡§®‡§æ‡§è‡§Ç‡§ó‡•á, ‡§ú‡§π‡§æ‡§Å ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§™‡§Ç‡§ï‡•ç‡§§‡§ø ‡§Æ‡•á‡§Ç `image_path\\tjson_string` ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_labels = []\n",
    "for img_name, ann_list in annotations.items():\n",
    "    line = f\"images/{img_name}\\t{json.dumps(ann_list)}\"\n",
    "    det_labels.append(line)\n",
    "\n",
    "# ‡§á‡§∏‡•á ‡§è‡§ï ‡§´‡§º‡§æ‡§á‡§≤ ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡•á‡§Ç\n",
    "with open('dataset/det_label.txt', 'w') as f:\n",
    "    f.write('\\n'.join(det_labels))\n",
    "\n",
    "print(\"dataset/det_label.txt ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ:\")\n",
    "!cat dataset/det_label.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 4: ‡§∞‡§ø‡§ï‡•â‡§ó‡•ç‡§®‡§ø‡§∂‡§® ‡§≤‡•á‡§¨‡§≤ ‡§Æ‡•á‡§Ç ‡§∞‡•Ç‡§™‡§æ‡§Ç‡§§‡§∞‡§£\n",
    "\n",
    "‡§π‡§Æ ‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§∂‡§® ‡§è‡§®‡•ã‡§ü‡•á‡§∂‡§® ‡§∏‡•á ‡§∂‡§¨‡•ç‡§¶ ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•ç‡§∞‡•â‡§™ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á ‡§î‡§∞ `rec_label.txt` ‡§´‡§º‡§æ‡§á‡§≤ ‡§¨‡§®‡§æ‡§è‡§Ç‡§ó‡•á, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç `crop_path\\tlabel` ‡§π‡•ã‡§§‡§æ ‡§π‡•à‡•§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_labels = []\n",
    "crop_counter = 0\n",
    "\n",
    "for img_name, ann_list in annotations.items():\n",
    "    img = Image.open(f\"dataset/images/{img_name}\")\n",
    "    for ann in ann_list:\n",
    "        points = ann['points']\n",
    "        transcription = ann['transcription']\n",
    "        \n",
    "        # ‡§∏‡•Ä‡§Æ‡§æ ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§ï‡•ç‡§∞‡•â‡§™ ‡§ï‡§∞‡•á‡§Ç\n",
    "        x_coords = [p[0] for p in points]\n",
    "        y_coords = [p[1] for p in points]\n",
    "        box = (min(x_coords), min(y_coords), max(x_coords), max(y_coords))\n",
    "        cropped_img = img.crop(box)\n",
    "        \n",
    "        # ‡§ï‡•ç‡§∞‡•â‡§™ ‡§ï‡•Ä ‡§ó‡§à ‡§õ‡§µ‡§ø ‡§ï‡•ã ‡§∏‡§π‡•á‡§ú‡•á‡§Ç\n",
    "        crop_filename = f\"word_crops/crop_{crop_counter:04d}.png\"\n",
    "        cropped_img.save(f\"dataset/{crop_filename}\")\n",
    "        \n",
    "        # ‡§∞‡§ø‡§ï‡•â‡§ó‡•ç‡§®‡§ø‡§∂‡§® ‡§≤‡•á‡§¨‡§≤ ‡§Æ‡•á‡§Ç ‡§ú‡•ã‡§°‡§º‡•á‡§Ç\n",
    "        rec_labels.append(f\"{crop_filename}\\t{transcription}\")\n",
    "        crop_counter += 1\n",
    "\n",
    "# ‡§∞‡§ø‡§ï‡•â‡§ó‡•ç‡§®‡§ø‡§∂‡§® ‡§≤‡•á‡§¨‡§≤ ‡§´‡§º‡§æ‡§á‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç\n",
    "with open('dataset/rec_label.txt', 'w') as f:\n",
    "    f.write('\\n'.join(rec_labels))\n",
    "    \n",
    "print(\"dataset/rec_label.txt ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ:\")\n",
    "!cat dataset/rec_label.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡§∞‡§£ 5: ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó/‡§µ‡•à‡§≤‡§ø‡§°‡•á‡§∂‡§® ‡§µ‡§ø‡§≠‡§æ‡§ú‡§® ‡§¨‡§®‡§æ‡§è‡§Å\n",
    "\n",
    "‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§Ü‡§™‡§ï‡•ã ‡§Ö‡§™‡§®‡•á ‡§≤‡•á‡§¨‡§≤ ‡§ï‡•ã ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó `train.txt` ‡§î‡§∞ `val.txt` ‡§´‡§º‡§æ‡§á‡§≤‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§≠‡§æ‡§ú‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(label_file_path, train_ratio=0.8):\n",
    "    with open(label_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    random.shuffle(lines)\n",
    "    train_size = int(len(lines) * train_ratio)\n",
    "    train_lines = lines[:train_size]\n",
    "    val_lines = lines[train_size:]\n",
    "    \n",
    "    base_name = os.path.splitext(label_file_path)[0]\n",
    "    \n",
    "    with open(f\"{base_name}_train.txt\", 'w') as f:\n",
    "        f.writelines(train_lines)\n",
    "        \n",
    "    with open(f\"{base_name}_val.txt\", 'w') as f:\n",
    "        f.writelines(val_lines)\n",
    "    \n",
    "    print(f\"{base_name}_train.txt ‡§î‡§∞ {base_name}_val.txt ‡§¨‡§®‡§æ‡§è ‡§ó‡§è‡•§\")\n",
    "\n",
    "# ‡§°‡§ø‡§ü‡•á‡§ï‡•ç‡§∂‡§® ‡§î‡§∞ ‡§∞‡§ø‡§ï‡•â‡§ó‡•ç‡§®‡§ø‡§∂‡§® ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§≠‡§æ‡§ú‡§® ‡§¨‡§®‡§æ‡§è‡§Å\n",
    "create_splits('dataset/det_label.txt')\n",
    "create_splits('dataset/rec_label.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‡§Ö‡§¨ ‡§Ü‡§™‡§ï‡§æ `dataset` ‡§´‡§º‡•ã‡§≤‡•ç‡§°‡§∞ PaddleOCR ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ü‡•ç‡§∞‡•á‡§®‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
